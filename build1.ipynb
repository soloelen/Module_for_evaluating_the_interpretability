{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T02:05:00.128572Z",
     "start_time": "2023-04-21T02:04:57.131142Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.training_pipeline import train_model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T02:02:40.089760Z",
     "start_time": "2023-04-21T01:29:41.511100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_model_pipeline(\"resnet\", freeze_conv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_pipeline(\"vgg\", freeze_conv=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:22:38.586836Z",
     "start_time": "2023-05-01T23:22:35.421719Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.models import ResNet18, VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:22:43.503255Z",
     "start_time": "2023-05-01T23:22:38.592349Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet = ResNet18().load(\"./models/resnet.pth\")\n",
    "vgg = VGG16().load(\"./models/vgg.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:22:43.514545Z",
     "start_time": "2023-05-01T23:22:43.509215Z"
    }
   },
   "outputs": [],
   "source": [
    "model = resnet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:04.539549Z",
     "start_time": "2023-05-01T23:23:04.521816Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import requests\n",
    "import cv2\n",
    "import torchvision\n",
    "\n",
    "from PIL.Image import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "from src.interpretation.interpretation_functions import layer_cam_gen, guided_backprop_gen, gradpp_cam_gen, saliency_gen, grad_cam_gen\n",
    "from src.interpretation.image_utils import im_show, preprocess, ClassifierOutputSoftmaxTarget, \\\n",
    "    confidence_change_apply_cam, \\\n",
    "    get_target_index, preprocess_image, view, to_plot_bbox, iou_loc\n",
    "from src.interpretation.metrics import deletion_metric, deletion_game, preservation_metric, preservation_game, \\\n",
    "    average_drop_item, \\\n",
    "    avg_drop_list, increase_in_confidence_item, increase_in_confidence_list, topk_img, sparsity, iou_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:06.322944Z",
     "start_time": "2023-05-01T23:23:05.542426Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_cifar10_data():\n",
    "    '''\n",
    "    Return train_data, train_labels, test_data, test_labels\n",
    "    The shape of data returned would be as it is in the data-set N X 3072\n",
    "\n",
    "    We don't particularly need the metadata - the mapping of label numbers to real labels\n",
    "    '''\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        data_dic = unpickle(\"data/cifar-10-batches-py/data_batch_\" + str(i))\n",
    "        if i == 1:\n",
    "            train_data = data_dic[b'data']\n",
    "        else:\n",
    "            train_data = np.append(train_data, data_dic[b'data'])\n",
    "        train_labels += data_dic[b'labels']\n",
    "\n",
    "    test_data_dic = unpickle(\"data/cifar-10-batches-py/test_batch\")\n",
    "    test_data = test_data_dic[b'data']\n",
    "    test_labels = test_data_dic[b'labels']\n",
    "    names=unpickle(\"data/cifar-10-batches-py/batches.meta\")\n",
    "    \n",
    "    return train_data, np.array(train_labels), test_data, np.array(test_labels), names[b'label_names']\n",
    "\n",
    "train_data, train_labels, test_data, test_labels,names=load_cifar10_data()\n",
    "IMG_IDX=13\n",
    "train_data = train_data.reshape((-1,3072)).reshape(-1, 3, 32, 32).transpose([0, 2, 3, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:06.598722Z",
     "start_time": "2023-05-01T23:23:06.582425Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "np.random.seed(42)\n",
    "batch_idx = np.random.choice(np.arange(len(train_data)), 100, replace=False)\n",
    "batch = train_data[batch_idx]\n",
    "batch = np.array([cv2.resize(i, (224, 224), cv2.INTER_AREA) for i in batch])\n",
    "batch_labels = train_labels[batch_idx]\n",
    "minbatch_idx = np.random.choice(np.arange(len(train_data)), 10, replace=False)\n",
    "minibatch = train_data[minbatch_idx]\n",
    "minibatch = np.array([cv2.resize(i, (224, 224), cv2.INTER_AREA) for i in minibatch])\n",
    "minibatch_labels  = [train_data[minbatch_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:07.787495Z",
     "start_time": "2023-05-01T23:23:07.779585Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель        \n",
    "Resnet\n",
    "Deletion Game diffs=0.15189067,  perc=6.4\n",
    "Preservation Game diffs=0.015533727 perc= 990.0\n",
    "Avg Drop 53.79\n",
    "Increase in Confidence  0.15\n",
    "Sparsity 2.53 \n",
    "\n",
    "Модель        \n",
    "VGG\n",
    "Deletion Game diffs=0.136 perc=10.0  \n",
    "Preservation Game diffs=0.0012 perc= 990.0\n",
    "Avg Drop 58.94\n",
    "Increase in Confidence  0.12\n",
    "Sparsity 2.533"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:19.244809Z",
     "start_time": "2023-05-01T23:23:09.623479Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img in minibatch:\n",
    "    res, gray_res = layer_cam_gen(model, (img/255).astype(np.float32), target_layers=[model.layer4])\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(res)\n",
    "    #plt.imshow(torch.movedim(torchvision.io.read_image(path + file), 0, -1).numpy())\n",
    "    #plt.imshow(res)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:23.180562Z",
     "start_time": "2023-05-01T23:23:19.249343Z"
    }
   },
   "outputs": [],
   "source": [
    "for img in minibatch:\n",
    "    #img = transforms(torchvision.io.read_image(path + file)).float()\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    tensor = transform(img).to(device)\n",
    "    res = saliency_gen(tensor, model)\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(res.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:23:39.927735Z",
     "start_time": "2023-05-01T23:23:35.810960Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gray = []\n",
    "for img in batch:\n",
    "    res, gray_res = guided_backprop_gen(model, (img/255).astype(np.float32), target_layers=[model.layer4])\n",
    "    gray.append(gray_res)   \n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)\n",
    "\n",
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===GUIDED BACKPROP===\")\n",
    "print(\"Deletion game:\", np.mean(diffs), np.mean(perc))\n",
    "print(\"Preservation game:\", np.mean(diffs_preservation), np.mean(percs_preservation))\n",
    "print(\"Avg drop:\", avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels))\n",
    "print(\"Increace in Confidence:\", increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels))\n",
    "print(\"Sparsity\", sparsity(cam=gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guided_backprop_gen(model, (img/255).astype(np.float32), target_layers=[model.layer4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, 0.3, 5) + [0.12869766, 0.0007029077, 56.446118944070264, 0.16, 0.6030237999578316]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gray = []\n",
    "for img in batch:\n",
    "    res, gray_res = grad_cam_gen(model, (img/255).astype(np.float32), target_layers=[model.layer4])\n",
    "    gray.append(gray_res)   \n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)\n",
    "\n",
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===GRADCAM===\")\n",
    "print(\"Deletion game:\", np.mean(diffs), np.mean(perc))\n",
    "print(\"Preservation game:\", np.mean(diffs_preservation), np.mean(percs_preservation))\n",
    "print(\"Avg drop:\", avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels))\n",
    "print(\"Increace in Confidence:\", increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels))\n",
    "print(\"Sparsity\", sparsity(cam=gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gray = []\n",
    "for img in batch:\n",
    "    res, gray_res = guided_backprop_gen(model, (img/255).astype(np.float32), target_layers=[model.layer4])\n",
    "    gray.append(gray_res)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:32:11.061911Z",
     "start_time": "2023-05-01T23:23:39.932884Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:32:50.192380Z",
     "start_time": "2023-05-01T23:32:50.179814Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(diffs), np.mean(perc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preservation Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:46:46.496482Z",
     "start_time": "2023-05-01T23:32:55.258999Z"
    }
   },
   "outputs": [],
   "source": [
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-01T23:46:46.515942Z",
     "start_time": "2023-05-01T23:46:46.499688Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(diffs_preservation), np.mean(percs_preservation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increase in Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Sparsity = {sparsity(cam=gray)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import patches\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "with open(\"export-result (cifar10FINAL).ndjson\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "list_iou = []\n",
    "\n",
    "for i in range(len(data[\"a\"])):\n",
    "  name_dict = data[\"a\"][i][\"data_row\"][\"external_id\"]\n",
    "  \n",
    "  bbox_dict_i = data[\"a\"][i][\"projects\"][list(data[\"a\"][i][\"projects\"].keys())[0]][\"labels\"][0][\"annotations\"][\"objects\"][0][\"bounding_box\"]\n",
    "  bb_top_i = bbox_dict_i[\"top\"]\n",
    "  bb_left_i = bbox_dict_i[\"left\"]\n",
    "  bb_height_i = bbox_dict_i[\"height\"]\n",
    "  bb_width_i = bbox_dict_i[\"width\"]\n",
    "  im = Image.open(f\"for_labelig_cifar/data_for_labeling/{name_dict}\")\n",
    "  res, gray_res = guided_backprop_gen(model, \n",
    "                               im_show(f\"for_labelig_cifar/data_for_labeling/{name_dict}\"),\n",
    "                               target_layers= [model.layer4])\n",
    "  bb_arr = np.array([bb_top_i, bb_left_i, bb_top_i + bb_height_i, bb_left_i + bb_width_i])\n",
    "  iou_i = iou_loc(bb_arr, gray_res)\n",
    "  list_iou.append(iou_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IOU Average: {np.mean(list_iou)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_iou = []\n",
    "\n",
    "for i in range(len(data[\"a\"])):\n",
    "  name_dict = data[\"a\"][i][\"data_row\"][\"external_id\"]\n",
    "  \n",
    "  bbox_dict_i = data[\"a\"][i][\"projects\"][list(data[\"a\"][i][\"projects\"].keys())[0]][\"labels\"][0][\"annotations\"][\"objects\"][0][\"bounding_box\"]\n",
    "  bb_top_i = bbox_dict_i[\"top\"]\n",
    "  bb_left_i = bbox_dict_i[\"left\"]\n",
    "  bb_height_i = bbox_dict_i[\"height\"]\n",
    "  bb_width_i = bbox_dict_i[\"width\"]\n",
    "  im = Image.open(f\"for_labelig_cifar/data_for_labeling/{name_dict}\")\n",
    "  res, gray_res = guided_backprop_gen(model, \n",
    "                               im_show(f\"for_labelig_cifar/data_for_labeling/{name_dict}\"),\n",
    "                               target_layers= [model.avgpool])\n",
    "  bb_arr = np.array([bb_top_i, bb_left_i, bb_top_i + bb_height_i, bb_left_i + bb_width_i])\n",
    "  iou_i = iou_loc(bb_arr, gray_res)\n",
    "  list_iou.append(iou_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IOU Average: {np.mean(list_iou)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gray = []\n",
    "for img in batch:\n",
    "    res, gray_res = guided_backprop_gen(model, (img/255).astype(np.float32), target_layers=[model.avgpool])\n",
    "    gray.append(gray_res)   \n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)\n",
    "\n",
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===GUIDED BACKPROP===\")\n",
    "print(\"Deletion game:\", np.mean(diffs), np.mean(perc))\n",
    "print(\"Preservation game:\", np.mean(diffs_preservation), np.mean(percs_preservation))\n",
    "print(\"Avg drop:\", avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels))\n",
    "print(\"Increace in Confidence:\", increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels))\n",
    "print(\"Sparsity\", sparsity(cam=gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "gray = []\n",
    "for img in batch:\n",
    "    res, gray_res = grad_cam_gen(model, (img/255).astype(np.float32), target_layers=[model.avgpool])\n",
    "    gray.append(gray_res)\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)\n",
    "\n",
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===GRADCAM===\")\n",
    "print(\"Deletion game:\", np.mean(diffs), np.mean(perc))\n",
    "print(\"Preservation game:\", np.mean(diffs_preservation), np.mean(percs_preservation))\n",
    "print(\"Avg drop:\", avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels))\n",
    "print(\"Increace in Confidence:\", increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels))\n",
    "print(\"Sparsity\", sparsity(cam=gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in minibatch:\n",
    "    res, gray_res = layer_cam_gen(model, (img/255).astype(np.float32), target_layers=[model.avgpool])\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(res)\n",
    "    #plt.imshow(torch.movedim(torchvision.io.read_image(path + file), 0, -1).numpy())\n",
    "    #plt.imshow(res)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in minibatch:\n",
    "    #img = transforms(torchvision.io.read_image(path + file)).float()\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    tensor = transform(img).to(device)\n",
    "    res = saliency_gen(tensor, model)\n",
    "    f, axarr = plt.subplots(1, 2)\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(res.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "diffs, percs = [], []\n",
    "for img, g in zip(batch, gray):\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = deletion_game(img.to(device), cam=g, model=model, gray_res=g)\n",
    "    diffs.append(diff_), percs.append(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diffs), np.mean(perc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preservation Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_preservation, percs_preservation = [], []\n",
    "for img in batch:\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    diff_, perc, cam_ = preservation_game(img.to(device), cam=g, model=model, cam_=g)\n",
    "    diffs_preservation.append(diff_), percs_preservation.append(perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diffs_preservation), np.mean(percs_preservation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_drop_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, index=batch_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increace in Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase_in_confidence_list([transform(b).unsqueeze(0) for b in batch], np.array(gray), model, batch_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Sparsity = {sparsity(cam=gray)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
